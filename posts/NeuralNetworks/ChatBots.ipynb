{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Practical Chatbots\"\n",
    "author: \"Isaac Flath\"\n",
    "date: \"2021-06-23\"\n",
    "description: \"Improving business processes using ML-Based chatbots\"\n",
    "categories: [Neural Networks]\n",
    "image: \"../_TopicImages/NeuralNetwork.jpg\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I developed a process and app for creating and deploying chatbots for support and question answering purposes for Novetta.  This solution focused on practicality including minimizing the dataset needed, minimizing training/retraining needed, eliminating the need to retrain if policies change, and empowering domain experts to expand and improve the responses of without requiring a ML engineer for every tweak.\n",
    "\n",
    "This approach was built on the sentence transformer (siamese BERT) architecture and the core machine learning technology was semantic similarity.  I built it using dash, but any deployment method could be used (slack bot, email bot, web app, etc.)\n",
    "\n",
    "To read the blog post [click here](https://web.archive.org/web/20221114235423/https://www.novetta.com/2021/06/chatbots/)\n",
    "\n",
    "\n",
    "> Note:  I believe this approach is still valid today as of 2024.  The more common approach today would be to use an LLM, and pull in the answer to the prompt (RAG) to let the LLM generate a response rather than using a fixed set of responses.  However, in some cases it is advantageous to have vetted responses with no risk of halucination.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
